{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import time\n",
    "from qiskit_entropy.utils import *\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータを取得\n",
    "config = load_config('/home/mitsukism/qiskit_entropy/vn_ent_qubits10_training_config.json')\n",
    "\n",
    "qubits = config[\"qubits\"]\n",
    "num_wires = config[\"num_wires\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "N = config[\"N\"]\n",
    "seed = config[\"seed\"]\n",
    "num_shots = config[\"num_shots\"]\n",
    "num_of_epochs = config[\"num_of_epochs\"]\n",
    "learning_rate = config[\"learning_rate\"]\n",
    "num_of_samples = config[\"num_of_samples\"]\n",
    "dimension = config[\"dimension\"]\n",
    "hidden_layer = config[\"hidden_layer\"]\n",
    "\n",
    "device = qml.device(\"default.qubit\", wires=num_wires, shots=num_shots)\n",
    "@qml.qnode(device)\n",
    "def measure_rho(param, circuit_structure, qubits, rotations=[qml.RX, qml.RY, qml.RZ]):\n",
    "    obj_wires = range(qubits)   \n",
    "\n",
    "    qml.Hadamard(wires=0)\n",
    "\n",
    "    for gate_info in circuit_structure:\n",
    "        gate = gate_info[\"gate\"]\n",
    "        wires = gate_info[\"wires\"]\n",
    "        if gate == \"CNOT\":\n",
    "            qml.CNOT(wires=wires)\n",
    "        elif gate == \"PauliX\":\n",
    "            qml.PauliX(wires=wires[0])\n",
    "        elif gate == \"PauliY\":\n",
    "            qml.PauliY(wires=wires[0])\n",
    "        elif gate == \"PauliZ\":\n",
    "            qml.PauliZ(wires=wires[0])\n",
    "\n",
    "    qml.RandomLayers(param, wires=obj_wires, rotations=rotations)\n",
    "\n",
    "    result = [qml.sample(qml.PauliZ(i)) for i in range(len(obj_wires))]\n",
    "    return result\n",
    "\n",
    "class neural_function(nn.Module):\n",
    "    def __init__(self,dimension,hidden_layer):\n",
    "        super(neural_function, self).__init__()\n",
    "\n",
    "        self.dimension = dimension\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.lin1 = nn.Linear(self.dimension, self.hidden_layer)\n",
    "        self.lin_end = nn.Linear(self.hidden_layer, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        y = torch.sigmoid(self.lin1(input.float()))\n",
    "        y = self.lin_end(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_fn = neural_function(dimension, hidden_layer)\n",
    "param_init = np.random.random(qml.RandomLayers.shape(n_layers=num_layers, n_rotations=3))\n",
    "circuit_structure = load_circuit_structure_from_json('/home/mitsukism/qiskit_entropy/circuit_structure.json')\n",
    "print(circuit_structure)\n",
    "\n",
    "cost_func_store = []\n",
    "# start the training\n",
    "for epoch in range(1, num_of_epochs):\n",
    "    \n",
    "  # evaluate the gradient with respect to the quantum circuit parameters\n",
    "    gradients = np.zeros_like((param_init))\n",
    "    \n",
    "    for i in range(len(gradients)):\n",
    "        for j in range(len(gradients[0])):\n",
    "\n",
    "      # copy the parameters\n",
    "            shifted = param_init.copy()\n",
    "\n",
    "      # right shift the parameters\n",
    "            shifted[i, j] += np.pi/2\n",
    "\n",
    "      # forward evaluation\n",
    "            forward_sum = 0\n",
    "            result = measure_rho(shifted, circuit_structure, qubits)\n",
    "            for sample in range(num_of_samples):\n",
    "                sample_result_array = np.array([result[q][sample] for q in range(dimension)])\n",
    "                nn_result = neural_fn(torch.from_numpy(sample_result_array))\n",
    "                forward_sum += nn_result[0].detach().numpy()\n",
    "\n",
    "      # normalize the forward sum\n",
    "            forward_sum = forward_sum/num_of_samples\n",
    "\n",
    "      # left shift the parameters\n",
    "            shifted[i, j] -= np.pi\n",
    "\n",
    "      # backward evaluation\n",
    "            backward_sum = 0\n",
    "            result = measure_rho(shifted, circuit_structure, qubits)\n",
    "            for sample in range(num_of_samples):\n",
    "                sample_result_array = np.array([result[q][sample] for q in range(dimension)])\n",
    "                nn_result = neural_fn(torch.from_numpy(sample_result_array))\n",
    "                backward_sum += nn_result[0].detach().numpy()\n",
    "\n",
    "      # normalize the backward sum\n",
    "            backward_sum = backward_sum/num_of_samples\n",
    "      #print(backward_sum)\n",
    "\n",
    "      # parameter-shift rule\n",
    "            gradients[i, j] = - 0.5 * (forward_sum - backward_sum)\n",
    "    np.save(f\"/home/mitsukism/qiskit_entropy/vn_net_gradients/qubits10/gradients_epoch{epoch}_seed{seed}.npy\", gradients)\n",
    "\n",
    "  # first copy the quantum circuit parameters before updating it\n",
    "    prev_param_init = param_init.copy()\n",
    "\n",
    "  # update the quantum circuit parameters\n",
    "    param_init -= learning_rate*gradients\n",
    "\n",
    "  # evaluate the gradient with respect to the NN parameters\n",
    "    optimizer = optim.SGD(neural_fn.parameters(), lr=learning_rate)\n",
    "\n",
    "  # evaluate the first term\n",
    "    loss = 0\n",
    "    result = measure_rho(prev_param_init, circuit_structure, qubits)\n",
    "    for sample in range(num_of_samples):\n",
    "        # optimizer.zero_grad()\n",
    "        sample_result_array = np.array([result[q][sample] for q in range(dimension)])\n",
    "        random_result_array = np.random.choice([-1, 1], size=dimension)\n",
    "        sample_nn_result = neural_fn(torch.from_numpy(sample_result_array))\n",
    "        random_nn_result = neural_fn(torch.from_numpy(random_result_array))\n",
    "        loss_term = (torch.exp(random_nn_result[0]) - sample_nn_result[0]).to(\"cpu\")\n",
    "        loss += loss_term / num_of_samples\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(neural_fn.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "  # evaluate the cost function at these parameters\n",
    "    first_term = 0\n",
    "    result = measure_rho(param_init, circuit_structure, qubits)\n",
    "    for sample in range(num_of_samples):\n",
    "        sample_result_array = np.array([result[q][sample] for q in range(dimension)])\n",
    "        nn_result = neural_fn(torch.from_numpy(sample_result_array))\n",
    "        first_term += nn_result[0].detach().numpy()\n",
    "\n",
    "  # normalize the cost sum\n",
    "    first_term = first_term/num_of_samples\n",
    "\n",
    "  # # Second term evaluation\n",
    "    second_term = 0\n",
    "    for sample in range(num_of_samples):\n",
    "        result = np.random.choice([-1, 1], size=dimension)\n",
    "        nn_result = neural_fn(torch.from_numpy(result.flatten()))\n",
    "        second_term += np.exp(nn_result[0].detach().numpy())\n",
    "\n",
    "  # normalize the second term sum\n",
    "    second_term = second_term/num_of_samples\n",
    "\n",
    "    # add the cost function to the store\n",
    "    cost_func_store.append(np.log(N) - first_term + second_term - 1)\n",
    "  # save the cost function\n",
    "    np.save(f\"/home/mitsukism/qiskit_entropy/vn_net_cost/qubits10/cost_epoch{epoch}_seed{seed}.npy\", cost_func_store)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
